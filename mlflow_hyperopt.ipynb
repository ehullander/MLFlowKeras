{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from hyperopt import Trials, fmin, tpe, hp, STATUS_OK\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "mlflow.tensorflow.autolog(every_n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You would have to expose this containers port also\n",
    "#remote_server_uri = \"mlruns\" # set to your server URI\n",
    "remote_server_uri = \"http://10.0.0.115:5000\"\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(\"my-hypteropt-experiment3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples     \n",
      "Epoch 1/10                                            \n",
      "60000/60000 - 32s - loss: 0.2396 - acc: 0.9277 - f1_score: 0.9205 - val_loss: 0.0486 - val_acc: 0.9847 - val_f1_score: 0.9848\n",
      "\n",
      "Epoch 2/10                                            \n",
      "60000/60000 - 31s - loss: 0.0852 - acc: 0.9742 - f1_score: 0.9745 - val_loss: 0.0434 - val_acc: 0.9847 - val_f1_score: 0.9853\n",
      "\n",
      "Epoch 3/10                                            \n",
      "60000/60000 - 31s - loss: 0.0667 - acc: 0.9803 - f1_score: 0.9806 - val_loss: 0.0347 - val_acc: 0.9893 - val_f1_score: 0.9894\n",
      "\n",
      "Epoch 4/10                                            \n",
      "60000/60000 - 31s - loss: 0.0523 - acc: 0.9837 - f1_score: 0.9839 - val_loss: 0.0289 - val_acc: 0.9905 - val_f1_score: 0.9904\n",
      "\n",
      "Epoch 5/10                                            \n",
      "60000/60000 - 31s - loss: 0.0450 - acc: 0.9862 - f1_score: 0.9863 - val_loss: 0.0300 - val_acc: 0.9901 - val_f1_score: 0.9902\n",
      "\n",
      "Epoch 6/10                                            \n",
      "60000/60000 - 32s - loss: 0.0399 - acc: 0.9873 - f1_score: 0.9874 - val_loss: 0.0284 - val_acc: 0.9905 - val_f1_score: 0.9905\n",
      "\n",
      "Epoch 7/10                                            \n",
      "60000/60000 - 32s - loss: 0.0340 - acc: 0.9892 - f1_score: 0.9894 - val_loss: 0.0302 - val_acc: 0.9909 - val_f1_score: 0.9911\n",
      "\n",
      "Epoch 8/10                                            \n",
      "60000/60000 - 33s - loss: 0.0308 - acc: 0.9900 - f1_score: 0.9901 - val_loss: 0.0287 - val_acc: 0.9905 - val_f1_score: 0.9908\n",
      "\n",
      "Epoch 9/10                                            \n",
      "60000/60000 - 32s - loss: 0.0278 - acc: 0.9912 - f1_score: 0.9912 - val_loss: 0.0295 - val_acc: 0.9907 - val_f1_score: 0.9907\n",
      "\n",
      "Epoch 10/10                                           \n",
      "60000/60000 - 33s - loss: 0.0275 - acc: 0.9909 - f1_score: 0.9909 - val_loss: 0.0265 - val_acc: 0.9913 - val_f1_score: 0.9915\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                                \n",
      "Epoch 1/10                                                                       \n",
      "60000/60000 - 32s - loss: 2.2857 - acc: 0.1322 - f1_score: 0.0000e+00 - val_loss: 2.2423 - val_acc: 0.2389 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 2/10                                                                       \n",
      "60000/60000 - 32s - loss: 2.2151 - acc: 0.2353 - f1_score: 0.0000e+00 - val_loss: 2.1565 - val_acc: 0.4182 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 3/10                                                                       \n",
      "60000/60000 - 34s - loss: 2.1271 - acc: 0.3482 - f1_score: 0.0000e+00 - val_loss: 2.0465 - val_acc: 0.5716 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 4/10                                                                       \n",
      "60000/60000 - 32s - loss: 2.0115 - acc: 0.4450 - f1_score: 0.0000e+00 - val_loss: 1.8984 - val_acc: 0.6728 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 5/10                                                                       \n",
      " 10%|â–ˆ         | 1/10 [07:32<48:02, 320.25s/trial, best loss: 0.9848133325576782]"
     ]
    }
   ],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    # returns batch-wise averge f1, not weighted\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def train(constants, hyperparams):\n",
    "\n",
    "    #mlflow.start_run()\n",
    "    with mlflow.start_run():\n",
    "        params = {**constants, **hyperparams}\n",
    "\n",
    "        batch_size = int(params['batch_size'])\n",
    "        num_classes = int(params['num_classes'])\n",
    "        epochs = int(params['epochs'])\n",
    "        lr = float(params['lr'])\n",
    "        optimizer_str = params['optimizer_str']\n",
    "\n",
    "        # input image dimensions\n",
    "        img_rows, img_cols = 28, 28\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "        # the data, split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5  )]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                         activation='relu',\n",
    "                         input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                      optimizer=optimizer_str,\n",
    "                      # user defined metrics that get reported\n",
    "                      metrics=['accuracy', f1_score])\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=2,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=(x_test, y_test))\n",
    "\n",
    "    #mlflow.end_run()\n",
    "    return {'loss': min(history.history['val_f1_score']), 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# Keep parallelism at or below number of hyperparams\n",
    "search_space = {\n",
    "    'lr': hp.uniform('lr', 1e-6, 1e-4),\n",
    "    'optimizer_str': hp.choice('optimizer_str', ['RMSprop', 'Adam', 'Adadelta'])\n",
    "}\n",
    "\n",
    "constants = {\n",
    "    'batch_size': 128,\n",
    "    'epochs': 10,\n",
    "    'num_classes': 10\n",
    "}\n",
    "\n",
    "#hyperopt\n",
    "\n",
    "train_func = partial(train, constants)\n",
    "\n",
    "# using default experiment\n",
    "best = fmin(train_func, space=search_space,\n",
    "            algo=tpe.suggest, max_evals=10, trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 3.989865204889641e-05, 'optimizer_str': 2}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x7f07fe0d9b38>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.choice('optimizer_str', ['RMSprop', 'Adam', 'Adadelta'])['optimizer_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
