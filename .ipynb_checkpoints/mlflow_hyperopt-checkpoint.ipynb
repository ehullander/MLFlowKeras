{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from hyperopt import Trials, fmin, tpe, hp, STATUS_OK\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import datetime\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "mlflow.tensorflow.autolog(every_n_iter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'my-hypteropt-experiment3' does not exist. Creating a new experiment\n"
     ]
    }
   ],
   "source": [
    "# You would have to expose this containers port also\n",
    "#remote_server_uri = \"mlruns\" # set to your server URI\n",
    "remote_server_uri = \"http://10.0.0.115:5000\"\n",
    "mlflow.set_tracking_uri(remote_server_uri)\n",
    "mlflow.set_experiment(\"my-hypteropt-experiment3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020/11/11 06:02:27 WARNING mlflow.tracking.context.git_context: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from                                 \n",
      "https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "    8192/11490434 [..............................]    \n",
      " - ETA: 0s                                            \n",
      "                                                     \n",
      "  122880/11490434 [..............................]    \n",
      " - ETA: 4s                                            \n",
      "                                                     \n",
      "  319488/11490434 [..............................]    \n",
      " - ETA: 3s                                            \n",
      "                                                     \n",
      " 1343488/11490434 [==>...........................]    \n",
      " - ETA: 1s                                            \n",
      "                                                     \n",
      " 3424256/11490434 [=======>......................]    \n",
      " - ETA: 0s                                            \n",
      "                                                     \n",
      " 5996544/11490434 [==============>...............]    \n",
      " - ETA: 0s                                            \n",
      "                                                     \n",
      " 8552448/11490434 [=====================>........]    \n",
      " - ETA: 0s                                            \n",
      "                                                     \n",
      "11042816/11490434 [===========================>..]    \n",
      " - ETA: 0s                                            \n",
      "                                                     \n",
      "11493376/11490434 [==============================]    \n",
      " - 0s 0us/step                                        \n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?trial/s, best loss=?]WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 60000 samples, validate on 10000 samples     \n",
      "60000/60000 - 30s - loss: 0.2306 - acc: 0.9298 - f1_score: 0.9232 - val_loss: 0.0530 - val_acc: 0.9829 - val_f1_score: 0.9813\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                               \n",
      "60000/60000 - 34s - loss: 0.2115 - acc: 0.9373 - f1_score: 0.9318 - val_loss: 0.0518 - val_acc: 0.9825 - val_f1_score: 0.9825\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                               \n",
      "60000/60000 - 32s - loss: 0.2419 - acc: 0.9262 - f1_score: 0.9207 - val_loss: 0.0608 - val_acc: 0.9799 - val_f1_score: 0.9798\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                               \n",
      "60000/60000 - 33s - loss: 0.2250 - acc: 0.9316 - f1_score: 0.9265 - val_loss: 0.0514 - val_acc: 0.9838 - val_f1_score: 0.9842\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                               \n",
      "60000/60000 - 31s - loss: 2.2803 - acc: 0.1500 - f1_score: 0.0000e+00 - val_loss: 2.2445 - val_acc: 0.4285 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                               \n",
      "60000/60000 - 31s - loss: 0.2249 - acc: 0.9313 - f1_score: 0.9259 - val_loss: 0.0645 - val_acc: 0.9795 - val_f1_score: 0.9797\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                \n",
      "60000/60000 - 32s - loss: 2.2823 - acc: 0.1407 - f1_score: 0.0000e+00 - val_loss: 2.2386 - val_acc: 0.2561 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                \n",
      "60000/60000 - 31s - loss: 2.2784 - acc: 0.1706 - f1_score: 0.0000e+00 - val_loss: 2.2440 - val_acc: 0.3697 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                \n",
      "60000/60000 - 33s - loss: 0.2325 - acc: 0.9294 - f1_score: 0.9245 - val_loss: 0.0576 - val_acc: 0.9826 - val_f1_score: 0.9828\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples                \n",
      "60000/60000 - 33s - loss: 0.2379 - acc: 0.9276 - f1_score: 0.9211 - val_loss: 0.0523 - val_acc: 0.9811 - val_f1_score: 0.9819\n",
      "\n",
      "100%|██████████| 10/10 [05:37<00:00, 33.72s/trial, best loss: 0.0]\n"
     ]
    }
   ],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    # returns batch-wise averge f1, not weighted\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "def train(constants, hyperparams):\n",
    "\n",
    "    #mlflow.start_run()\n",
    "    with mlflow.start_run():\n",
    "        params = {**constants, **hyperparams}\n",
    "\n",
    "        batch_size = int(params['batch_size'])\n",
    "        num_classes = int(params['num_classes'])\n",
    "        epochs = int(params['epochs'])\n",
    "        lr = float(params['lr'])\n",
    "        optimizer_str = params['optimizer_str']\n",
    "\n",
    "        # input image dimensions\n",
    "        img_rows, img_cols = 28, 28\n",
    "        input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "        # the data, split between train and test sets\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "        x_train = x_train.astype('float32')\n",
    "        x_test = x_test.astype('float32')\n",
    "        x_train /= 255\n",
    "        x_test /= 255\n",
    "\n",
    "        # convert class vectors to binary class matrices\n",
    "        y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "        y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "        callbacks = [tf.keras.callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5  )]\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                         activation='relu',\n",
    "                         input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "                      optimizer=optimizer_str,\n",
    "                      metrics=['accuracy', f1_score])\n",
    "\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=2,\n",
    "                            callbacks=callbacks,\n",
    "                            validation_data=(x_test, y_test))\n",
    "\n",
    "    #mlflow.end_run()\n",
    "    return {'loss': min(history.history['val_f1_score']), 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# Keep parallelism at or below number of hyperparams\n",
    "search_space = {\n",
    "    'lr': hp.uniform('lr', 1e-6, 1e-4),\n",
    "    'optimizer_str': hp.choice('optimizer_str', ['RMSprop', 'Adam', 'Adadelta'])\n",
    "}\n",
    "\n",
    "constants = {\n",
    "    'batch_size': 128,\n",
    "    'epochs': 1,\n",
    "    'num_classes': 10\n",
    "}\n",
    "\n",
    "train_func = partial(train, constants)\n",
    "\n",
    "# using default experiment\n",
    "best = fmin(train_func, space=search_space,\n",
    "            algo=tpe.suggest, max_evals=10, trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
